* Zeitplanung

|                                       | ~Dauer  | Beginn                    | Delta | Ende            |
|---------------------------------------+---------+---------------------------+-------+-----------------|
| Aufsetzen Kafka Cluster               | 5 Tage  | <2016-04-11 Mo>           |       | <2016-04-15 Fr> |
| Haskell Microservice Producer         | 5 Tage  | <2016-04-18 Mo>           |       | <2016-04-22 Fr> |
| Haskell Microservice Consumer         | 3 Tage  | <2016-04-25 Mo>           |       | <2016-04-27 Mi> |
| Spring Microservice Producer/Consumer | 5 Tage  | <2016-04-28 Do>           |       | <2016-05-04 Mi> |
| Dokumentation schreiben               | 10 Tage | wann immer etwas auffällt |       | <2016-05-18 Mi> |
| Korrektur /Abgabe                     |         |                           |       |                 |

* Journal
** <2016-04-11 Mo>
*** DONE Docker aufsetzen                                   :Aufsetzen_Kafka:
    CLOSED: [2016-04-12 Di 12:27]
    ~brew cask install dockertoolbox~
*** DONE Docker Compose installieren                        :Aufsetzen_Kafka:
    CLOSED: [2016-04-12 Di 12:27]
    in toolbox enthalten
*** DONE Docker aufsetzen                                   :Aufsetzen_Kafka:
    CLOSED: [2016-04-12 Tue 16:25]
    Guide: https://docs.docker.com/mac/step_one/

** <2016-04-12 Di>
*** DONE Repository und Dokumentation aufsetzen               :Dokumentation:
    CLOSED: [2016-04-12 Di 12:26]
    Ich werde ein Git Repository unter [[https://github.com/kRITZCREEK/praxisprojekt][GitHub]] führen, in dem ich alle relevanten
    Artefakte aufbewahre.

    Die Dokumentation werde ich mit ~org-mode~ schreiben und mittels
    latex-export mit XeLateX kompilieren.

    Wenn man die Schriftarten ~Gentium Plus~, ~Charis SIL~ und ~Dejavu Mono~
    installiert hat, lässt sich der org export mit xelatex kompilieren.

*** DONE Bibtex Datei anlegen                                 :Dokumentation:
    CLOSED: [2016-04-12 Di 14:00]
*** DONE Bibtex Datei in org build einbauen                   :Dokumentation:
    CLOSED: [2016-04-12 Di 14:00]
*** DONE Latex auf dem Mac aufsetzen                          :Dokumentation:
    CLOSED: [2016-04-12 Tue 15:57]
    ~brew cask install mactex~
    ~brew tap caskroom/fonts~
    ~brew cask install font-gentium-plus~
    ~brew cask install font-charis-sil~
    ~brew cask install font-dejavu-sans~
** <2016-04-13 Wed>
*** DONE unter OSX erfolgreich mit dem german & csquotes package kompilieren :Dokumentation:
    CLOSED: [2016-04-13 Wed 09:45]
    jetzt auf \usepackage[ngerman]{babel} umgestiegen
*** DONE Docker image anwerfen                              :Aufsetzen_Kafka:
    CLOSED: [2016-04-13 Wed 09:27]

    Guide:http://wurstmeister.github.io/kafka-docker/

#+BEGIN_SRC sh
    git clone git@github.com:wurstmeister/kafka-docker.git
    cd kafka-docker
    docker-machine ip # 192.168.99.100
    # KAFKA_ADVERTISED_HOST_NAME in docker-compose.yml
    # auf `docker-machine ip` setzen
    docker-compose up
    # In a second Docker shell
    docker-compose scale kafka=2
    docker-compose ps
    #          Name                        Command               State                          Ports
    # ----------------------------------------------------------------------------------------------------------------------
    # kafkadocker_kafka_1       start-kafka.sh                   Up      0.0.0.0:32769->9092/tcp
    # kafkadocker_kafka_2       start-kafka.sh                   Up      0.0.0.0:32770->9092/tcp
    # kafkadocker_zookeeper_1   /bin/sh -c /usr/sbin/sshd  ...   Up      0.0.0.0:32768->2181/tcp, 22/tcp, 2888/tcp, 3888/tcp

    ./start-kafka-shell.sh `docker-machine ip` `docker-machine ip`:32768

    # Unable to find image 'wurstmeister/kafka:latest' locally # Pulling repository
    # docker.io/wurstmeister/kafka # Network timed out while trying to connect to
    # https://index.docker.io/v1/repositories/wurstmeister/kafka/images. You may
    # want to check your internet connection or if you are behind a proxy.

    # http://stackoverflow.com/questions/31990757/network-timed-out-while-trying-to-connect-to-https-index-docker-io
    docker-machine restart default
    eval $(docker-machine env default)
    docker-machine regenerate-certs default

    $KAFKA_HOME/bin/kafka-topics.sh --create --topic topic \
        --partitions 4 --zookeeper $ZK --replication-factor 2
    # Created topic "topic".

    $KAFKA_HOME/bin/kafka-topics.sh --describe --topic topic --zookeeper $ZK
    # Topic:topic	PartitionCount:4	ReplicationFactor:2	Configs:
    #   Topic: topic	Partition: 0	Leader: 1001	Replicas: 1001,1002	Isr: 1001,1002
    #   Topic: topic	Partition: 1	Leader: 1002	Replicas: 1002,1001	Isr: 1002,1001
    #   Topic: topic	Partition: 2	Leader: 1001	Replicas: 1001,1002	Isr: 1001,1002
    #   Topic: topic	Partition: 3	Leader: 1002	Replicas: 1002,1001	Isr: 1002,1001

    # In der ersten Shell:
    $KAFKA_HOME/bin/kafka-console-producer.sh --topic=topic --broker-list=`broker-list.sh`

    # In der zweiten Shell:
    $KAFKA_HOME/bin/kafka-console-consumer.sh --topic=topic --zookeeper=$ZK

    # Zeilen die ich jetzt in der ersten Shell eingebe kommen in der zweiten Shell raus :)
    # Wenn ich dem consumer ein --from-beginning mitgebe, bekommt er alle Messages nochmal

#+END_SRC
    
    Unter Linux muss noch getestet werden.
*** DONE Kafka Cluster in Docker konfigurieren, sodass simples Skript funktioniert :Aufsetzen_Kafka:
    CLOSED: [2016-04-13 Wed 10:37]
    - In ~docker-compose.yaml~ ~KAFKA_ADVERTISED_HOST_NAME~ auf Rückgabe von
      ~docker-machine ip~ setzen.
*** DONE Maximal 2 Level an Kapiteln                          :Dokumentation:
    CLOSED: [2016-04-13 Wed 10:06]
*** DONE librdkafka installieren                           :Haskell_Producer:
    CLOSED: [2016-04-13 Wed 11:05]
    ~brew install librdkafka~ Installiert leider eine sehr alte 0.8er Version
    Selbst kompilieren:
    #+BEGIN_SRC sh
    ./configure
    make

    # openssl missing
    # https://github.com/phusion/passenger/issues/1630
    brew install openssl
    brew link opennssl --force

    sudo make install
    #+END_SRC
    Unter Windows könnte das schwierig sein

*** DONE Haskell Producer Projekt aufsetzen                :Haskell_Producer:
    CLOSED: [2016-04-13 Wed 11:32]
*** DONE haskakafka installieren und Example projekt kopieren :Haskell_Producer:
    CLOSED: [2016-04-13 Wed 11:32]
*** DONE Von außerhalb der Docker Shell mit dem Cluster sprechen :Aufsetzen_Kafka:Haskell_Producer:
    CLOSED: [2016-04-13 Wed 11:33]
    In docker-compose.yaml Broker Port öffnen:
    "9092" -> "9092:9092"

    Aus Haskell heraus auf `docker-machine ip`:9092 verbinden

*** DONE Topic Schema definieren, dass verwendet werden soll :Aufsetzen_Kafka:
    CLOSED: [2016-04-13 Wed 17:10]
**** Entitäten
     - Kunde
     - Warenkorb
     - Produkt
     - Bestellung
**** Protokoll
     Da Kafka zunächst einmal nur Text transportiert, verwenden wir einen JSON
     Wrapper um wesentliche Metadaten in jeder Message zu speichern. Hier haben
     wir uns für folgende Felder entschieden.

***** id :: UUID (JSON String)
      A uuid that uniquely identifies an event (not an entity).
***** key :: String
      A unique identifier of the entity (product, basket, order, etc) this event is about.
      This can be the id/uuid of the entity or any other string that defines uniquely this entity.
      Should be the same for all the events of the same entity.
      Should also be used as the Kafka key for partitioning purposes (so all events for the same entity go to the same partition).
***** time :: Long
      The time in milliseconds since epoch (ex: System.currentTimeMillis() in Java)
***** type :: String
      The type/name of this event. Ex.: product.changed, order.created, basket.deleted, etc.
      Should be in the past tense to make it clear the change already happened.
***** payload
      Object
      The complete entity this event is about serialized as JSON object.

*** DONE Topic Schema in Haskell abbilden                  :Haskell_Producer:
    CLOSED: [2016-04-13 Wed 17:11]
      
** <2016-04-14 Thu> 
*** DONE Lenses für Schema                                 :Haskell_Producer:
    CLOSED: [2016-04-13 Wed 22:59]
*** DONE To/FromJSON für Schema                            :Haskell_Producer:
    CLOSED: [2016-04-13 Wed 22:59]
*** DONE time library in haskell client benutzen           :Haskell_Producer:
    CLOSED: [2016-04-13 Wed 22:59]
    [2016-04-13 Wed]
    [[file:~/Documents/praxisprojekt/haskell-producer/src/Model.hs::newtype%20UTCTime%20=%20UTCTime%20String]]
* Offene TODOs
** Aufsetzen Kafka Cluster
*** TODO Skript zum initialen befüllen von Kafka mit Topics anlegen :Aufsetzen_Kafka:
** Haskell Microservice Producer
** Haskell Microservice Consumer
** Spring Microservice Producer/Consumer
** Dokumentation schreiben
*** TODO Abstrakt schreiben, dass den praktischen Teil einfängt :Dokumentation:
*** TODO Bibtex Datei mit Referenzen befüllen                 :Dokumentation:
*** TODO Inhaltsverzeichnes / Literaturverzeichnis Titel auf deutsch umstellen :Dokumentation:
*** TODO Titelseite erstellen                                 :Dokumentation:

*** TODO Prinzip der Automatisierung in Microservices beschreiben :Dokumentation:
    [2016-04-13 Wed]
    [[file:~/Documents/praxisprojekt/Dokumentation/praxisprojekt.org::*Automatisierung][Automatisierung]]

* Literatursnippets
** Building Microservices
*** 50-51
    All too often, it seems, the existing, wellunderstood standards and
    technology are ignored in favor of new standards that can only be
    implemented using brand-new technology—conveniently provided by the same
    companies that help design the new standards in the first place!
*** 56
    Make sure you know what you’re getting: keep your middleware dumb, and keep
    the smarts in the endpoints
*** 57
    The associated complexity with event-driven architectures and asynchronous
    programming in general leads me to believe that you should be cautious in
    how eagerly you start adopting these ideas. Ensure you have good monitoring
    in place, and strongly consider the use of correlation IDs, which allow you
    to trace requests across process boundaries.
* Tasks
** DONE Fix default notes file shenanigens
   CLOSED: [2016-04-13 Wed 07:12]
   [2016-04-13 Wed]
   [[file:~/dotfiles/.spacemacs.d/init.el::"~/Documents/praxisprojekt/Dokumentation/notizen.org"))]]

   ~with-eval-after-load 'org~ hat's geregelt
