* Zeitplanung

|                                       | ~Dauer  | Beginn                    | Delta | Ende            |
|---------------------------------------+---------+---------------------------+-------+-----------------|
| Aufsetzen Kafka Cluster               | 5 Tage  | <2016-04-11 Mo>           |       | <2016-04-15 Fr> |
| Haskell Microservice Produktservice   | 5 Tage  | <2016-04-18 Mo>           |       | <2016-04-22 Fr> |
| Haskell Microservice Warenkorbservice | 3 Tage  | <2016-04-25 Mo>           |       | <2016-04-27 Mi> |
| Dokumentation schreiben               | 10 Tage | wann immer etwas auffällt |       | <2016-05-18 Mi> |
| Korrektur /Abgabe                     |         |                           |       |                 |

* Journal
** <2016-04-11 Mo>
*** DONE Docker aufsetzen                                   :Aufsetzen_Kafka:
    CLOSED: [2016-04-12 Di 12:27]
    ~brew cask install dockertoolbox~
*** DONE Docker Compose installieren                        :Aufsetzen_Kafka:
    CLOSED: [2016-04-12 Di 12:27]
    in toolbox enthalten
*** DONE Docker aufsetzen                                   :Aufsetzen_Kafka:
    CLOSED: [2016-04-12 Tue 16:25]
    Guide: https://docs.docker.com/mac/step_one/

** <2016-04-12 Di>
*** DONE Repository und Dokumentation aufsetzen               :Dokumentation:
    CLOSED: [2016-04-12 Di 12:26]
    Ich werde ein Git Repository unter [[https://github.com/kRITZCREEK/praxisprojekt][GitHub]] führen, in dem ich alle relevanten
    Artefakte aufbewahre.

    Die Dokumentation werde ich mit ~org-mode~ schreiben und mittels
    latex-export mit XeLateX kompilieren.

    Wenn man die Schriftarten ~Gentium Plus~, ~Charis SIL~ und ~Dejavu Mono~
    installiert hat, lässt sich der org export mit xelatex kompilieren.

*** DONE Bibtex Datei anlegen                                 :Dokumentation:
    CLOSED: [2016-04-12 Di 14:00]
*** DONE Bibtex Datei in org build einbauen                   :Dokumentation:
    CLOSED: [2016-04-12 Di 14:00]
*** DONE Latex auf dem Mac aufsetzen                          :Dokumentation:
    CLOSED: [2016-04-12 Tue 15:57]
    ~brew cask install mactex~
    ~brew tap caskroom/fonts~
    ~brew cask install font-gentium-plus~
    ~brew cask install font-charis-sil~
    ~brew cask install font-dejavu-sans~
** <2016-04-13 Wed>
*** DONE unter OSX erfolgreich mit dem german & csquotes package kompilieren :Dokumentation:
    CLOSED: [2016-04-13 Wed 09:45]
    jetzt auf \usepackage[ngerman]{babel} umgestiegen
*** DONE Docker image anwerfen                              :Aufsetzen_Kafka:
    CLOSED: [2016-04-13 Wed 09:27]

    Guide:http://wurstmeister.github.io/kafka-docker/

#+BEGIN_SRC sh
    git clone git@github.com:wurstmeister/kafka-docker.git
    cd kafka-docker
    docker-machine ip # 192.168.99.100
    # KAFKA_ADVERTISED_HOST_NAME in docker-compose.yml
    # auf `docker-machine ip` setzen
    docker-compose up
    # In a second Docker shell
    docker-compose scale kafka=2
    docker-compose ps
    #          Name                        Command               State                          Ports
    # ----------------------------------------------------------------------------------------------------------------------
    # kafkadocker_kafka_1       start-kafka.sh                   Up      0.0.0.0:32769->9092/tcp
    # kafkadocker_kafka_2       start-kafka.sh                   Up      0.0.0.0:32770->9092/tcp
    # kafkadocker_zookeeper_1   /bin/sh -c /usr/sbin/sshd  ...   Up      0.0.0.0:32768->2181/tcp, 22/tcp, 2888/tcp, 3888/tcp

    ./start-kafka-shell.sh `docker-machine ip` `docker-machine ip`:32768

    # Unable to find image 'wurstmeister/kafka:latest' locally # Pulling repository
    # docker.io/wurstmeister/kafka # Network timed out while trying to connect to
    # https://index.docker.io/v1/repositories/wurstmeister/kafka/images. You may
    # want to check your internet connection or if you are behind a proxy.

    # http://stackoverflow.com/questions/31990757/network-timed-out-while-trying-to-connect-to-https-index-docker-io
    docker-machine restart default
    eval $(docker-machine env default)
    docker-machine regenerate-certs default

    $KAFKA_HOME/bin/kafka-topics.sh --create --topic topic \
        --partitions 4 --zookeeper $ZK --replication-factor 2
    # Created topic "topic".

    $KAFKA_HOME/bin/kafka-topics.sh --describe --topic topic --zookeeper $ZK
    # Topic:topic	PartitionCount:4	ReplicationFactor:2	Configs:
    #   Topic: topic	Partition: 0	Leader: 1001	Replicas: 1001,1002	Isr: 1001,1002
    #   Topic: topic	Partition: 1	Leader: 1002	Replicas: 1002,1001	Isr: 1002,1001
    #   Topic: topic	Partition: 2	Leader: 1001	Replicas: 1001,1002	Isr: 1001,1002
    #   Topic: topic	Partition: 3	Leader: 1002	Replicas: 1002,1001	Isr: 1002,1001

    # In der ersten Shell:
    $KAFKA_HOME/bin/kafka-console-producer.sh --topic=topic --broker-list=`broker-list.sh`

    # In der zweiten Shell:
    $KAFKA_HOME/bin/kafka-console-consumer.sh --topic=topic --zookeeper=$ZK

    # Zeilen die ich jetzt in der ersten Shell eingebe kommen in der zweiten Shell raus :)
    # Wenn ich dem consumer ein --from-beginning mitgebe, bekommt er alle Messages nochmal

#+END_SRC
    
    Unter Linux muss noch getestet werden.
*** DONE Kafka Cluster in Docker konfigurieren, sodass simples Skript funktioniert :Aufsetzen_Kafka:
    CLOSED: [2016-04-13 Wed 10:37]
    - In ~docker-compose.yaml~ ~KAFKA_ADVERTISED_HOST_NAME~ auf Rückgabe von
      ~docker-machine ip~ setzen.
*** DONE Maximal 2 Level an Kapiteln                          :Dokumentation:
    CLOSED: [2016-04-13 Wed 10:06]
*** DONE librdkafka installieren                           :Haskell_Produktservice:
    CLOSED: [2016-04-13 Wed 11:05]
    ~brew install librdkafka~ Installiert leider eine sehr alte 0.8er Version
    Selbst kompilieren:
    #+BEGIN_SRC sh
    ./configure
    make

    # openssl missing
    # https://github.com/phusion/passenger/issues/1630
    brew install openssl
    brew link opennssl --force

    sudo make install
    #+END_SRC
    Unter Windows könnte das schwierig sein

*** DONE Haskell Producer Projekt aufsetzen                :Haskell_Produktservice:
    CLOSED: [2016-04-13 Wed 11:32]
*** DONE haskakafka installieren und Example projekt kopieren :Haskell_Produktservice:
    CLOSED: [2016-04-13 Wed 11:32]
*** DONE Von außerhalb der Docker Shell mit dem Cluster sprechen :Aufsetzen_Kafka:Haskell_Produktservice:
    CLOSED: [2016-04-13 Wed 11:33]
    In docker-compose.yaml Broker Port öffnen:
    "9092" -> "9092:9092"

    Aus Haskell heraus auf `docker-machine ip`:9092 verbinden

*** DONE Topic Schema definieren, dass verwendet werden soll :Aufsetzen_Kafka:
    CLOSED: [2016-04-13 Wed 17:10]
**** Entitäten
     - Kunde
     - Warenkorb
     - Produkt
     - Bestellung
**** Protokoll
     Da Kafka zunächst einmal nur Text transportiert, verwenden wir einen JSON
     Wrapper um wesentliche Metadaten in jeder Message zu speichern. Hier haben
     wir uns für folgende Felder entschieden.

***** id :: UUID (JSON String)
      A uuid that uniquely identifies an event (not an entity).
***** key :: String
      A unique identifier of the entity (product, basket, order, etc) this event is about.
      This can be the id/uuid of the entity or any other string that defines uniquely this entity.
      Should be the same for all the events of the same entity.
      Should also be used as the Kafka key for partitioning purposes (so all events for the same entity go to the same partition).
***** time :: Long
      The time in milliseconds since epoch (ex: System.currentTimeMillis() in Java)
***** type :: String
      The type/name of this event. Ex.: product.changed, order.created, basket.deleted, etc.
      Should be in the past tense to make it clear the change already happened.
***** payload
      Object
      The complete entity this event is about serialized as JSON object.

*** DONE Topic Schema in Haskell abbilden                  :Haskell_Produktservice:
    CLOSED: [2016-04-13 Wed 17:11]
      
** <2016-04-14 Thu>

*** DONE Lenses für Schema                                 :Haskell_Produktservice:
    CLOSED: [2016-04-14 Thu 10:57]
*** DONE To/FromJSON für Schema                            :Haskell_Produktservice:
    CLOSED: [2016-04-14 Thu 10:57]
*** DONE time library in haskell client benutzen           :Haskell_Produktservice:
    CLOSED: [2016-04-14 Thu 10:57]
    [2016-04-13 Wed]
    [[file:~/Documents/praxisprojekt/haskell-producer/src/Model.hs::newtype%20UTCTime%20=%20UTCTime%20String]]
*** DONE Inhaltsverzeichnes / Literaturverzeichnis Titel auf deutsch umstellen :Dokumentation:
    CLOSED: [2016-04-14 Thu 14:54]
    # #+LANGUAGE: de
*** DONE Titelseite erstellen                                 :Dokumentation:
    CLOSED: [2016-04-14 Thu 17:34]

** <2016-04-20 Wed>
*** DONE Neue Projektstruktur:                              :Aufsetzen_Kafka:
    CLOSED: [2016-04-22 Fri 10:19]
    - Dokumentation
    - produktservice
    - warenkorbservice
    - kafka-docker
*** DONE Producer der ein Produkt pro Sekunde erstellt/updated :Haskell_Produktservice:
    CLOSED: [2016-04-20 Wed 14:27]
    produktservice exe kann arbitrary Produkte verschicken
** <2016-04-22 Fri>
*** DONE Docker Image aus Produktservice             :Haskell_Produktservice:
    CLOSED: [2016-05-10 Tue 09:54]
    https://github.com/mgreenly/dockerimages/tree/master/alpine-stack
    #+BEGIN_SRC sh
   /Documents/praxisprojekt/produktservice master
   > which alpine-dockerize
   /Users/christophhegemann/.local/bin/alpine-dockerize
   
   ~/Documents/praxisprojekt/produktservice master
   > alpine-dockerize
   latest: Pulling from mgreenly/alpine-stack
   4d06f2521e4f: Pull complete
   d098f7f3ad34: Pull complete
   92668451a664: Pull complete
   a421b0b0f303: Pull complete
   Digest: sha256:7db7d3f07f2eef299006b3f677453d5dc3948ab9b8a4e136ab51c6a90a18da05
   Status: Downloaded newer image for mgreenly/alpine-stack:latest
   Downloading lts-5.13 build plan ...
   Downloaded lts-5.13 build plan.
   Caching build plan
   Updating package index Hackage (mirrored at https://s3.amazonaws.com/hackage.fpcomplete.com/00-index.tar.gz) ...
   Downloading package index from https://s3.amazonaws.com/hackage.fpcomplete.com/00-index.tar.gz
   Populating index cache ...
   Populated index cache. 
   /data/../haskell-proto: canonicalizePath: does not exist (No such file or directory)
   find: -printf: unknown primary or operator

    #+END_SRC

    Das Problem ist, dass die shared library nicht im Docker image verfügbar ist.

    Außerdem muss ich schauen wie man librdkafka installieren würde.
*** DONE Docker Image aus Warenkorbservice         :Haskell_Warenkorbservice:
    CLOSED: [2016-05-10 Tue 09:54]
** <2016-05-10 Tue>
*** DONE Binde listings Umgebung fuer Code ein
    CLOSED: [2016-05-10 Tue 13:55]
    [2016-04-14 Thu]
    [[file:~/Documents/praxisprojekt/Dokumentation/praxisprojekt.org::*Modell][Modell]]
*** TODO Umgebungsvariablen für die Services bestimmen :Haskell_Produktservice:Haskell_Warenkorbservice:
**** KAFKA_ADVERTISED_HOST
**** POSTGRES Variablen
* Offene TODOs
** Aufsetzen Kafka Cluster
*** TODO Skript zum initialen befüllen von Kafka mit Topics anlegen :Aufsetzen_Kafka:
** Haskell Produktservice
** Haskell Warenkorbservice
*** TODO CLI? Interface für API calls              :Haskell_Warenkorbservice:
*** TODO Model für Warenkorbservice                :Haskell_Warenkorbservice:
*** TODO JSON Instanzen / Transformationen         :Haskell_Warenkorbservice:
*** TODO Warenkorbservice Transstack mit STM State :Haskell_Warenkorbservice:
** Spring Microservice Producer/Consumer
** Dokumentation schreiben
*** TODO Abstrakt schreiben, dass den praktischen Teil einfängt :Dokumentation:
*** TODO Bibtex Datei mit Referenzen befüllen                 :Dokumentation:
*** TODO Den Aufbau des Prototypen beschreiben                :Dokumentation:
    Besonders cool wären hier Grafiken/Komponentendiagramme
*** TODO Den Produktservice beschreiben                       :Dokumentation:
*** TODO Den Warenkorbservice beschreiben                     :Dokumentation:
*** TODO Prinzip der Automatisierung in Microservices beschreiben :Dokumentation:
    [2016-04-13 Wed]
    [[file:~/Documents/praxisprojekt/Dokumentation/praxisprojekt.org::*Automatisierung][Automatisierung]]
* Literatursnippets
** Building Microservices
*** 22
    Microservices are small, autonomous services that work together
*** 50-51
    All too often, it seems, the existing, wellunderstood standards and
    technology are ignored in favor of new standards that can only be
    implemented using brand-new technology—conveniently provided by the same
    companies that help design the new standards in the first place!
*** 56
    Make sure you know what you’re getting: keep your middleware dumb, and keep
    the smarts in the endpoints
*** 57
    The associated complexity with event-driven architectures and asynchronous
    programming in general leads me to believe that you should be cautious in
    how eagerly you start adopting these ideas. Ensure you have good monitoring
    in place, and strongly consider the use of correlation IDs, which allow you
    to trace requests across process boundaries.
*** 127
    Docker is being used in production by multiple companies. It provides many
    of the benefits of lightweight containers in terms of efficiency and speed
    of provisioning, together with the tools to avoid many of the downsides.
** Enterprise Integration Patterns
* Tasks
** DONE Fix default notes file shenanigens
   CLOSED: [2016-04-13 Wed 07:12]
   [2016-04-13 Wed]
   [[file:~/dotfiles/.spacemacs.d/init.el::"~/Documents/praxisprojekt/Dokumentation/notizen.org"))]]

   ~with-eval-after-load 'org~ hat's geregelt
