#+BEGIN_SRC emacs-lisp :results silent :exports none
    (unless (find "kc-report" org-latex-classes :key 'car
                  :test 'equal))

  (add-to-list 'org-latex-classes
               '("kc-report"
                 "\\documentclass[11pt,a4paper]{scrreprt}
  \\usepackage[T1]{fontenc}
  \\usepackage{fontspec}
  \\usepackage{graphicx}
  \\defaultfontfeatures{Mapping=tex-text}
  \\setromanfont{Charis SIL}
  \\setsansfont{Gentium Plus}
  \\setmonofont[Scale=0.8]{DejaVu Sans Mono}
  \\usepackage{geometry}
        [NO-DEFAULT-PACKAGES]
        [NO-PACKAGES]"
                 ("\\chapter{%s}" . "\\chapter*{%s}")
                 ("\\section{%s}" . "\\section*{%s}")
                 ("\\subsection{%s}" . "\\subsection*{%s}")
                 ("\\subsubsection{%s}" . "\\subsubsection*{%s}")
                 ("\\paragraph{%s}" . "\\paragraph*{%s}")
                 ("\\subparagraph{%s}" . "\\subparagraph*{%s}")))

    (setq org-latex-pdf-process
      '("latexmk -xelatex -shell-escape -interaction=nonstopmode -f -pdf %f"))
    (setq org-latex-listings 'minted)
#+END_SRC

#+AUTHOR: Christoph Hegemann
#+TITLE: Isolation & Virtualisierung von Services mit Docker
#+LATEX_CLASS: kc-report
# #+LATEX_CLASS_OPTIONS: [a4paper, oneside, abstract=true, BCOR=11pt, fontsize=11pt, draft=true, titlepage=false, headsepline=true]
#+LATEX_CLASS_OPTIONS: [a4paper, oneside, abstract=true, BCOR=11pt, fontsize=11pt, draft=false, titlepage=true, headsepline=true]
#+LATEX_HEADER: \usepackage[hyperref,x11names]{xcolor}
#+LATEX_HEADER: \usepackage[colorlinks=true,urlcolor=SteelBlue4,linkcolor=Firebrick4]{hyperref}
#+LATEX_HEADER: \usepackage[normalem]{ulem}
#+LATEX_HEADER: \usepackage[ngerman]{babel}
#+LATEX_HEADER: \usepackage{csquotes}
#+LATEX_HEADER: \usepackage{epigraph}
#+LATEX_HEADER: \setlength{\epigraphwidth}{0.8\textwidth}
#+LATEX_HEADER: \usepackage[cache=false]{minted}
#+LATEX_HEADER: \usemintedstyle{emacs}
#+LATEX_HEADER: \setcounter{tocdepth}{1}
#+LATEX_HEADER: \setcounter{secnumdepth}{1}
#+LATEX_HEADER: \pagestyle{headings}
#+LATEX_HEADER: \usepackage[backend=biber, style=science, backref=true]{biblatex}

#+LATEX_HEADER: \titlehead{\center{Technische Hochschule Köln}}
#+LATEX_HEADER: \subject{Praxisprojekt}
#+LATEX_HEADER: \subtitle{Im Kontext der Implementierung und Integration von Microservices}
#+LATEX_HEADER: \publishers{Betreut von Prof.\ Dr.\ Christian Kohls}
#+LATEX_HEADER: \addbibresource{literatur.bib}

#+BIBLIOGRAPHY: literatur.bib
#+LANGUAGE: de
#+OPTIONS: H:4 ':t

#+BEGIN_abstract

Bei der REWE Digital wird ein großes Softwareprojekt umgesetzt. Um die große
Anzahl an Teams, Entwicklern und Systemen zu bändigen hat man sich für eine
Microservice Architektur entschieden. Das Aufteilen der Domäne in viele kleine,
unabhängige Bereiche erlaubt es Komplexität auf der Software Ebene gering zu
halten, bringt jedoch neue Schwierigkeiten im Bereich von Operations, Deployment
und Integration mit sich.

Ein Ansatz um die gestiegene Komplexität von Provisionierung und Integration von
Microservices anzugehen ist Virtualisierung mithilfe von Containertechnologie,
wie die derzeit verbreiteste Lösung, das von der gleichnamigen Firma entwickelte
Docker. In diesem Praxisprojekt werde ich mit der Implementierung von
Microservices und ihrem Deployment mithilfe von Docker beschäftigen und meine
Fortschritte sowie Rückschläge dokumentieren.

#+END_abstract

* Motivation

#+BEGIN_LATEX
\epigraph{Move fast and break things. Unless you are breaking stuff, you are not moving fast enough.}
{\textsc{Mark Zuckerberg}}
#+END_LATEX
** Großes Software Projekt bei der REWE Digital
*** Mehr als 20 Teams, je 5-7 Mitarbeiter
*** Hoher Featuredruck, kaum Maintenanceaufwand
*** Schnell wachsen
*** Agiles Vorgehen
*** Rapid Prototyping
** Microservice Architektur
*** Microservices
#+BEGIN_QUOTE
Microservices are small, autonomous services that work together

-- \textsc{Sam Newman}\cite{Newman-BuildingMicroservices}
#+END_QUOTE

    Auf kleinen Services lässt sich schnell iterieren. Sollte sich
    herausstellen, dass die falsche Herangehensweise gewählt wurde, kann ein
    bereits geschriebener Microservice in vertretbarem Zeitaufwand neu
    geschrieben werden.

    Durch die hohe Autonomie der Services können Teams parallel arbeiten und an
    vielen Stellen iterieren ohne sich gegenseitig zu behindern.

*** Korrelation Kommmunikationsstruktur -- Softwarestruktur
#+BEGIN_QUOTE
Organizations which design systems ... are constrained to produce designs
which are copies of the communication structures of these organizations.

-- Melvin E. Conway
#+END_QUOTE
*** Domain Driven Design
    Eric Evans \cite{Evans-DomainDrivenDesign}
** Integrationsstrategien
   Eine der wichtigsten Herausforderungen, die eine Microservice Architektur mit
   sich bringt, ist es verschiedene Services miteinander zu integrieren. Es muss
   sichergestellt werden, dass Services Daten austauschen können, untereinander
   konsistent sind und dennoch nicht zu eng gekoppelt sind. Es gibt verschiedene
   Integrationsstrategien, die man verfolgen kann.

   Ich werde im folgenden die /Integation über eine gemeinsame Datenbank/
   analysieren und anschließend die letztendlich gewählte Strategie des
   Messaging beschreiben.
*** Integration über eine gemeinsame (relationale) Datenbank
    #+BEGIN_QUOTE

    "If a family of integrated applications all rely on
    the same database, then you can be pretty sure that they are always
    consistent all of the time" \cite{Hohpe-EnterpriseIntegrationPatterns}

    #+END_QUOTE

    Klassischerweise integriert man verschiedene Applikationen und Services
    mithilfe einer geteilten relationen Datenbank. Diese Herangehensweise hat
    viele Vorteile:

    - Hohe Konsistenzgarantien

      Als einzige Quelle der Wahrheit, kann eine Datenbank mithilfe von
      Transaktionen dafür sorgen, dass niemals ein inkonsistenter Datenbestand
      abgespeichert werden kann.

    - Breite Unterstützung von SQL

      Es gibt für nahezu alle Sprachen und Frameworks hochwertige SQL
      Bibliotheken die sich seit vielen Jahren in der Industrie bewährt haben.

    - Ein gemeinsames Datenmodell

      Da alle Dienste mit dem selben Schema arbeiten, können schon früh
      Inkompatibilitäten zwischen den Services und Missverständnisse bei der
      Modellierung des Datenmodelles gefunden und geklärt werden.

    In einer Microservice Architektur birgt die geteilte Datenbank jedoch viele
    Nachteile.

    - Ein gemeinsames Datenmodell

      Alle Services müssen mit demselben Datenmodell arbeiten. Dies widerspricht
      ganz deutlich dem Prinzip der "Bounded Contexts" aus Domain Driven Design.
      Nicht jeder Service hat dieselbe Sicht auf eine Entität. Hier einen
      gemeinsamen Nenner zu finden, erfordert dass sich alle Teams einigen und
      jede Änderung am Datenmodell ist ein potentieller Breaking Change für
      jeden Service.

    - Implementierungsdetails liegen offen

      Ein Schema in einer Datenbank ist als eine API zu sehen, da jeder Client
      der Datenbank auf das Schema zugreifen kann. "The DB is effectively a very
      large, shared API that is also quite brittle."
      \cite{Newman-BuildingMicroservices}

      Ein Service legt also mit seinem Datenmodell einen großen Teil seiner
      Implementierung offen. Dies sorgt für Kopplung zwischen den Services und
      widerspricht damit eindeutig der Zielsetzung der Microservice Architektur.

    - Single Point of Failure

      In einer Architektur, die darauf ausgelegt ist, einzelne Services
      unabhängig voneinander zu machen um Ausfälle lokal zu halten und
      Fehlertolerant zu sein hat eine von allen Services verwendete Datenbank
      keinen Platz. Wenn diese ausfällt ist das gesamte System ausgefallen.

    - Performanz Probleme

      Da Konsistenzgarantien nur durch Locking und Transaktionen gewährleistet
      werden können, kann ein einziger Service der viel Last auf der Datenbank
      erzeugt, alle anderen Services mit "ausbremsen".
*** Messaging
#+BEGIN_QUOTE
Messaging makes applications loosely coupled by communicating asynchronously
-- Gregor Hohpe cite:Hohpe-EnterpriseIntegrationPatterns
#+END_QUOTE
    Bei Messaging senden sich verschiedene Systeme kleine Datenpakete über einen
    Messagebus. Dieser Messagebus, oder auch Messagebroker genannt, sorgt dafür
    das Nachrichten an die richtigen Empfänger zugestellt werden. Hierfür
    benötigt der Messagebus einige Funktionalitäten.

    - Er muss eine Queue von eingegangenen Messages verwalten
    - Er muss, falls das Empfängersystem nicht erreichbar ist, Nachrichten
      verwahren und zu einem späteren Zeitpunkt zustellen
    - Er muss gesendete Nachrichten auch nach der Zustellung aufbewahren und
      wieder abspielen können, um neu hinzugekommene Systeme auf den aktuellsten
      Stand bringen zu können.

    Bei der REWE digital hat man sich für das Messaging System *Apache Kafka*
    entschieden. Kafka wird auf seiner Website als /A high-throughput
    distributed messaging system/ angepriesen und hat einige interessante
    Charakteristiken, mit welchen ich mich in meiner Bachelorarbeit noch einmal
    genauer auseinander setzen werde. Für unsere Zwecke reicht es zunächst
    festzustellen, dass Kafka alle Anforderungen an einen Messagebus für die
    Systemintegration erfüllt.


* Der Prototyp
  Um die Tauglichkeit von Docker und Kafka zu untersuchen und kritische Fragen
  bereits frühzeitig aufdecken zu können, haben wir uns dafür entschieden einen
  Prototyp zu entwicklen, der sich der aktuellen Systemstruktur annähert und
  eine breite Menge an bekannten Szenarien und Schwierigkeiten abdeckt.

** Aufbau
  Es sollen zwei Services implementiert werden, die per Messaging über Kafka
  integriert und vollständig unabhängig voneinander in Docker Containern
  ausgerollt werden können. Weiterhin müssen sie unabhängig skalierbar sein und
  der Ausfall des einen Services darf den anderen Service nicht beeinflussen.

  Inhaltlich sollen die Services sich mit einer gemeinsamen Entität
  beschäftigen, auf die sie jedoch unterschiedliche Sichten haben. In Kafka wird
  diese Entität als ein Topic abgebildet, welcher von einem der Services als
  "Owner" oder Producer und von dem anderen Service als Consumer konsumiert
  wird. Für den Prototypen wurde sich für einen /Produktservice/ und einen
  /Warenkorbservice/ entschieden. Beide dieser Services, natürlich in
  komplexerer Form, finden sich auch in der tatsächlichen Anwendung bei REWE
  wieder.

  Der generelle Aufbau des Prototypen wird in [[fig:architektur-schaubild]]
  dargestellt.

  #+CAPTION: Aufbau Prototyp
  #+LABEL: fig:architektur-schaubild
  [[./bilder/architektur.eps]]


** Kommunikation & Protokoll
  Die Messages, mit denen die Services kommunizieren, sind in JSON enkodiert.
  Der JSON Standard (JavaScript Object Notation) ist ein weit verbreitetes,
  simples und menschenlesbares Austauschformat, welches vor allem im Bereich der
  Webentwicklung eingesetzt wird.

*** Message Wrapper
    Die in JSON serialisierten Entitäten werden in einen Message Wrapper
    eingepackt, der für die technische Umsetzung relevante Metadaten enthält.

#+BEGIN_SRC haskell
data Message a =
  Message
  { id      :: UUID -- identifiziert die Nachricht
  , key     :: Text -- identifiziert die Entität
  , time    :: UTCTime
  , type    :: Text -- Art der Änderung ("created", "modified", "deleted")
  , payload :: a
  }
#+END_SRC
    Der /Typparameter/ ~a~ lässt sich mit Java's Generics vergleichen. Er gibt
    an welchen Typ von Entität die Nachricht beinhaltet. Im Prototypen kann dies
    Beispielsweise ein ~Message Produkt~ ergeben.

** Bounded Context

    Dass die Services eine unterschiedliche Sicht auf dieselbe Entität, und damit
    auch unterschiedliche Datenmodelle haben, bildet einen der wichtigsten
    Begriffe des Domain Driven Design's ab. Der /Bounded Context/ beschreibt
    fachliche Bereiche innerhalb einer Domäne, in denen ein gemeinsames
    Verständnis für bestimmte Objekte und Entitäten besteht. Als Beispiel könnte
    man hier die Produktion der Lagerung innerhalb einer Fabrik gegenüberstellen.
    Beide Bereiche beschäftigen sich mit Produkten, innerhalb der Produktion sind
    jedoch Eigenschaften wie Fertigungsdauer und Rohmaterialien interessant,
    während sich das Lager mit Eigenschaften wie Gewicht, Größe und
    Haltbarkeitsdauer beschäftigt.

#+BEGIN_QUOTE
As you try to model a larger domain, it gets progressively harder to build a
single unified model. Different groups of people will use subtly different
vocabularies in different parts of a large organization.

-- \textsc{Martin Fowler}\cite{Fowler-BoundedContext}
#+END_QUOTE

    Um diese Situation auch in unserem Prototypen abzubilden, müssen die beiden
    gewählten Services, /Produktservice/ und /Warenkorbservice/ ein
    unterschiedliches Datenmodell für die selbe Entität, das *Produkt*, haben und an den
    Servicegrenzen zwischen den Repräsentationen konvertieren können.

** Produktservice
   Der Produktservice ist Owner des Produkt Topics. Er stellt eine API zur
   Verfügung, die es erlaubt Produktdaten zu ändern. Hier könnten in der
   Realität mehrere Anwendungen Produktdaten ändern. Beispiele wären eine
   Webanwendung, in der Fachmitarbeiter Änderungen durchführen, sowie ein
   regelmäßiger Dienst, der die neuesten Angebote und Rabattaktionen automatisch
   einspielt. In unserem Protoyp werden diese Änderungen zufällig generiert.

*** Modell
    Der Produktservice hat folgende Sicht auf die Produktentität:

    #+BEGIN_SRC haskell
      data Produkt = Produkt
        { id           :: String
        , name         :: String
        , beschreibung :: String
        , preis        :: Preis
        , rabatt       :: Prozent
        }
    #+END_SRC
    #+CAPTION: Produkt Modell des Produktservices
    Updates, die der Produktservice an Kafka schickt, enthalten eine Payload in
    dieser Form. Eine Entität vom Typ ~Produkt~ wird hierfür in das JSON Format
    /enkodiert/, im ~Message~ Wrapper eingepackt und an Kafka weitergereicht.

#+BEGIN_SRC haskell
  sendRandomProduct =
    produceMessage topic (KafkaSpecifiedPartition partition)  -- (4)
    . KafkaProduceMessage -- (4)
    . BSL.toStrict -- (3)
    . encode -- (2)
    =<< produkt -- (1)
#+END_SRC
    Der Operator für Komposition in Haskell ist der Punkt. Weil Komposition in
    der Mathematik "rückwärts" funktioniert, lässt sich der Code leichter
    rückwärts erklären.

    (1) Die ~produkt~ Methode ist im Prototypen als ein Generator definiert, der
    ~QuickCheck~ verwendet um zufällige Messages zu generieren, die Produkte
    enthalten.
#+BEGIN_SRC haskell
produkt :: IO (Message Produkt)
produkt = QC.generate QC.arbitrary
#+END_SRC

    ~QuickCheck~ arbeitet typgetrieben, und kann anhand der Typsignatur
    inferieren, dass es einen Generator für ~Message Produkt~ verwenden muss,
    den ich an anderer Stelle definiert habe.

    (2) Nachdem eine Message mit Produkt Inhalt generiert wurde, reichen wir es an
    ~encode~ weiter und enkodieren die Message damit in JSON.

    (3) Weil Haskell's Evaluierungsstrategie Lazy ist, die Kafka Bibliothek
    jedoch mit strikt evaluierten Werten arbeitet, müssen wir mit ~BSL.toStrict~
    die vollständige Evaluierungs unseres JSON Wertes erzwingen, bevor wir es an
    Kafka weiterreichen.

    (4) ~produceMessage~ ist eine Funktion aus der Kafka Client Bibliothek, die
    eine Nachricht für ein gegebenes Topic, an eine gegebene Partition schickt.

** Warenkorbservice

   Der Warenkorbservice ist Owner für kein Topic. Stattdessen verwaltet er die
   Warenkörbe der Kunden, die für die restlichen Services nicht zur Verfügung
   stehen.

*** Modell
    Der Warenkorbservice hat folgende Sicht auf die Produktentität:
    #+BEGIN_SRC haskell
      data Produkt =
        Produkt
        { id    :: String
        , name  :: String
        , preis :: Preis
        }
    #+END_SRC
    #+CAPTION: Produkt Modell des Warenkorbservices
    Hierbei fällt auf, dass der Warenkorb nur an einem Subset der Felder der
    Produktservice Produktentität Kafka interessiert ist. Weiterhin beschreibt
    das ~preis~ Attribut den Preis, auf den der Rabatt bereits angewendet wurde.

    Es wird also eine /Selektion/ auf die vorhandenen Felder angewendet, und die
    verbleibenden Felder werden weiter durch /Transformation/ & /Aggregation/ in
    ein Modell, das der Domäne des Warenkorbes[fn:artikel] entspricht,
    transformiert.

    Das /deserialisieren/ und /transformieren/ sieht im Code wie folgt aus:
#+BEGIN_SRC haskell
instance FromJSON Produkt where
  parseJSON = withObject "Produkt" $ \o ->
    Produkt
    <$> o .: "id"
    <*> o .: "name"
    <*> (berechnePreis <$> o .: "preis" <*> o.: "rabatt")
    where
      berechnePreis :: (Integral a) => a -> Double -> a
      berechnePreis preis rabatt = floor $ fromIntegral preis * (1 - rabatt / 100)
#+END_SRC

    Die vielen ~<$>~ und ~<*>~ sorgen für das automatische Propagieren von
    Fehlern beim deserialisieren der JSON Felder. Mithilfe der ~berechnePreis~
    Funktion fassen wir die ~preis~ und ~rabatt~ Felder des Produktes aus dem
    Produktservice zusammen.

[fn:artikel]
In Wirklichkeit ist der Begriff des *Preises* im E-Commerce noch
deutlich komplexer. Einem *Produkt* ist zunächst einmal gar kein Preis
zugewiesen. Stattdessen ist ein Produkt eine Einheit, die für die
Präsentation verwendet wird (zB. Kaffetasse). \\
Einen Preis hingegen weist man einem *Artikel* zu, der Elemente wie Art (zB.
Farbe), Region (Produkte haben in unterschiedlichen Regionen unterschiedliche
Preise) und Rabattaktionen beinhaltet.



* Infrastruktur und Provisionierung

#+BEGIN_LATEX
\epigraph{Ownership extends to all aspects of the service, from sourcing requirements to
building, deploying, and maintaining the application. \cite{Newman-BuildingMicroservices}}
{\textsc{Sam Newman}}
#+END_LATEX

  Um den Herausforderungen bei der Umsetzung einer Microservicearchitektur
  gerecht zu werden, ist es wichtig, dass die Infrastruktur die Autonomie und
  Flexibilität der Teams nicht untergräbt sondern unterstützt.

** Anforderungen an die Infrastruktur
*** Elastizität
    Einer der wesentlichen Vorteile von Microservices ist es, dass durch die
    strikte Trennung zwischen den Services möglich ist Services unabhängig
    voneinander zu skalieren und der aktuellen Last anzupassen.

    Ein Message Broker wie Kafka kann zu verschiedenen Zeiten unter variierender
    Last arbeiten haben. Zu Stoßzeiten werden sehr viele Services Messages
    produzieren und abrufen. Um diesen sich ändernden Anforderungen gerecht zu
    werden, muss Kafka so aufgesetzt werden, dass dynamisch neue Broker
    hinzugefügt oder heruntergefahren werden können.

*** Automatisierung
    Die Provisionierung und das Ausrollen von Services und dem Kafka Broker muss
    vollständig automatisiert werden. Dies ist notwendig um /Elastizität/
    überhaupt realisieren zu können. Weiterhin garantiert vollständige
    Automatisierung, dass auch andere Teams den Service für Integrationstests
    hochfahren können.
*** Resilienz
    Die Message Queue stellt einen /Single Point of Failure/ dar. Sollte sie
    ausfallen können die Services nicht miteinander kommunizieren und die
    Verfügbarkeit des Gesamtsystems kann nicht sichergestellt werden. Daher
    müssen Fallback Instanzen provisioniert werden, die einspringen wenn
    Ausfälle auftreten. Weiterhin müssen ausgefallene Instanzen automatisch
    neugestartet und provisioniert werden. Mit dem Thema der Resilienz werde ich
    mich im Zuge der Bachelorarbeit noch ausführlicher beschäftigen.

** Docker/Container Technologie
   Um die Anforderungen erfüllen zu können muss eine leichtgewichtige
   Virtualisierungslösung gefunden werden. Die Entscheidung fällt hierbei für
   mein Praxisprojekt auf Docker.
#+BEGIN_QUOTE
Docker is being used in production by multiple companies. It provides many
of the benefits of lightweight containers in terms of efficiency and speed
of provisioning, together with the tools to avoid many of the
downsides. cite:Newman-BuildingMicroservices 

-- Sam Newman
#+END_QUOTE
*** Warum Docker?
    "Docker aims to reduce the cycle time between code being written and code being
    tested, deployed, and used. It aims to make your applications portable, easy to
    build, and easy to collaborate on."\cite{Turnbull-TheDockerBook}

*** Terminologie und Bausteine von Docker
   - Docker Daemon

     Ein Hintergrundprozess, der die laufenden Docker Container verwaltet und
     auf Kommandos des Nutzer reagiert. Dieser Daemon kann auf der gleichen
     Maschine wie der Nutzer ausgeführt werden, oder remote auf einem Server.

   - Docker Client

     Ein Docker Client ist ein Programm mit dessen Hilfe der Nutzer Befehle an
     einen Docker Daemon senden kann. Üblicherweise verwendet man einen CLI
     (Command Line Interface) Client, es gibt aber auch bereits Clients mit
     einer graphischen Nutzeroberfläche (Kitematic).

   - Docker Images

     Ein Image ist der kleinste Building Block in der Docker Welt. Images werden
     aufeinander aufgesetzt und lassen sich in verschiedenen Projekten und
     Applikationen wiederverwenden. Ein Image beinhaltet dabei immer einen
     Befehl, wie zum Beispiel:
     1. Füge eine Datei hinzu
     2. Öffne einen Port
     3. Lade ein Source Archiv herunter
     4. Führe einen Shell Befehl aus
     5. ...

   - Docker Registry

     Eine Docker Registry ist ein Registry, bei der Nutzer ihre Images
     hochladen, versionieren und für andere Nutzer verfügbar machen können. Eine
     Docker Registry ist vergleichbar mit einem Git Server auf dem Entwickler
     ihren Source Code hochladen, versionieren und für andere Nutzer verfügbar
     machen können.

     Die Macher von Docker betreiben eine öffentliche Registry mit dem Namen
     Dockerhub. Dockerhub ist für Nutzer, die ihre Images öffentlich machen
     kostenlos, und für Unternehmen oder Nutzer die ihre Images privat verwalten
     wollen für Geld nutzbar.

     Weiterhin gibt es die Möglichkeit eine Registry selbst zu betreiben, wie es
     bei der REWE Digital der Fall ist. Hierfür sprechen einige Gründe:
     1. Mehr Kontrolle
     2. Keine Abhängigkeit von (Docker Macher)
     3. Images sind häufig mehrere 100MB groß und es ist daher schneller wenn
        die Registry nah bzw. im selben Datencenter wie die Container betrieben
        werden.

   - Docker Container

*** Infrastruktur versionierbar machen
    In Docker verwendet man sogenannte Dockerfiles um das Erzeugen von Images in
    reproduzierbaren Schritten festzuhalten. Diese Dockerfiles liegen in
    Textform vor, und lassen sich damit in ein Version Control System wie GIT
    einchecken und versionieren.

    Als Beispiel soll hier einmal das, mit Kommentaren versehene, Dockerfile für
    den Runtime Container dienen:

#+ATTR_LATEX: :caption dockerfile
#+BEGIN_SRC Dockerfile
# Es wird das fpco/stack-run base image verwendet, welches alle nötigen
# Laufzeitabhängigkeiten für kompilierte Haskell binaries enthält.
FROM fpco/stack-run:lts-5

# Da die Kafka Client Bibliothek librdkafka nicht in den offiziellen
# Ubuntu repositories verfügbar ist, müssen wir sie selbst kompilieren und
# installieren mit build-essential tools wie 'gcc' und 'make'

# curl benötigen wir, um den Quellcode für die Bibliothek herunterzuladen
RUN apt-get update && \
    apt-get install -y \
      curl build-essential

# Hier laden wir ein mit 'tar' komprimiertes Archiv herunter, welches
# den Quellcode für librdkafka enthält.
RUN curl -o /root/librdkafka-0.9.0.99.tar.gz -SL \
      https://github.com/edenhill/librdkafka/archive/0.9.0.99.tar.gz

# Wir entpacken das Archiv
RUN tar -xzf /root/librdkafka-0.9.0.99.tar.gz -C /root && \
    cd /root/librdkafka-0.9.0.99

# Jetzt kompilieren wir librdkafka und installieren die entstandene
# Bibliothek mit 'make install' nach '/usr/lib wo sie für unsere
# Binaries verfübar ist
RUN ./configure && \
    make && \
    make install

# Hier cachen wir das anfänglich heruntergeladene Archiv um es bei
# zukünftigen Durchläufen nicht mehr herunterladen zu müssen.
RUN cd / && \
    tar czf librdkafka-0.9.0.99.tar.gz \
    usr/local/include/librdkafka usr/local/lib/librdkafka*
#+END_SRC

   Dieses Dockerfile kann nun verwendet werden um das Laufzeitimage neu zu
   bauen.

   Einzelne Images können, analog zu Git, mit Tags versehen werden, sodass
   getagte Versionen eines Dockerimages leicht referenziert und als Bausteine
   für weitere Images verwendet werden können.

   Weiterhin lassen sich mit einem Tag versehene Images in eine /Docker
   Registry/ pushen. Von dort können sie dann herunterladen und ausgeführt
   werden, ohne sie erneut bauen zu müssen.

*** Image Hierarchie

    Die Docker Container, die die fertigen Services enthalten, werden aus den in
    [[fig:docker-images]] dargestellten Images zusammengebaut.

    #+ATTR_LATEX: :width 10cm
    #+LABEL: fig:docker-images
    #+CAPTION: Docker Images
    [[./bilder/infrastruktur.eps]]

    Die ~ubuntu~ und ~fpco/stack-run~ Images sind bereits vorhanden, und können
    so wie sie sind, als Grundlage verwendet werden. Das ~stack-kafka-run~ image
    wird durch das in [[Infrastruktur versionierbar machen]] gezeigte Dockerfile
    gebaut.

** Haskell Services und Docker
   Haskell's am weitesten verbreitete Buildtool /stack/ bringt bereits von Haus
   Docker Integration mit, und macht es einem als Entwickler sehr einfach.
   Hierbei können Einstellungen gemacht werden, mit denen das betroffene Haskell
   Projekt in einem *Build Container* gebaut und anschließend in einem viel
   kleineren *Run Container* verpackt wird.

#+NAME: stack.yaml
#+BEGIN_SRC yaml
docker:
  enable: true
  image: "kritzcreeek/stack-kafka-build"

image:
  container:
    name: "kritzcreeek/produktservice"
    base: "kritzcreeek/stack-kafka-run"
#+END_SRC

    Als Beispiel sehen wir hier die nötigen Einstellungen um den Produktservice
    vollständig mithilfe von docker und dem "kritzcreeek/stack-kafka-build"
    Image zu bauen.

    Der ~image~ Eintrag gibt dann an, dass wir aufbauend auf dem
    "kritzcreeek/stack-kafka-run" Image unsere kompilierten Build Artefakte in
    einem Image mit dem Namem "kritzcreeek/produktservice" zusammenfassen
    wollen.

*** Die verwendeten Images
   - Build image für Haskell Projekte

     Base Image: fpco/stack-build

     Beinhaltet Haskell Compiler und build tools + librdkafka dependency kritzcreeek/stack-kafka-build
   - Run image für Haskell Projekte
     Base Image fpco/stack-run

     Beinhaltet Laufzeitabhängigkeiten für Haskell Projekte. Das sind zum
     Beispiel Systembibliotheken die dynamisch gegen die Executable gelinkt
     sind.
       + buildtools (gcc etc.)
       + eventuell weitere Abhängigkeiten (openssl)
       + librdkafka dependency kritzcreeek/stack-kafka-run

   - Docker Konfiguration für Services geschieht in ~stack.yaml~
     - Gebaut werden die Projekte innerhalb des Build Containers
       (kritzcreeek/stack-kafka-build). Kommando: ~stack build~
     - Run Container für die Services werden auf das Run Image aufgesetzt.
       Kommando: ~stack image container~
     - Services können mittels ~docker run -d kritzcreeek/produktservice
       produktservice~ gestartet werden.
     - Services können nun mit in docker-compose aufgenommen und leichter
       konfiguriert werden.


* Fazit
\printbibliography
